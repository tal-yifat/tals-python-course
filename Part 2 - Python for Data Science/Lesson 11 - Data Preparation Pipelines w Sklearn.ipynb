{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "\n",
      "Pandas info\n",
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "# Which versions are installed?\n",
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"\\nPandas info\")\n",
    "print (pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset\n",
    "The original dataset arrives divided into two parts - train and test. We will append those into a single dataset and then split it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training set from web \n",
    "df_1 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True)\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test set\n",
    "df_2 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True, skiprows=1)\n",
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_1.append(df_2, ignore_index=True, sort=True)\n",
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36631, 15), (12211, 15))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's divide the dataset to train and test sets. \n",
    "df_combined = df_combined.sample(frac=1, random_state=0) \n",
    "# We are setting a random state so that our datasets are replicable and we can all work on the same sets. \n",
    "\n",
    "df_train = df_combined.iloc[:int(df_combined.shape[0] * .75)].copy()\n",
    "df_test = df_combined.iloc[int(df_combined.shape[0] * .75):].copy()\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['>=50K', 'age', 'capital-gain', 'capital-loss', 'education',\n",
       "       'education-num', 'fnlwgt', 'hours-per-week', 'marital-status',\n",
       "       'native-country', 'occupation', 'race', 'relationship', 'sex',\n",
       "       'workclass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36631, 14), (12211, 14), (36631,), (12211,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate predictors from the label\n",
    "X_train = df_train.drop('>=50K', axis=1)\n",
    "X_test = df_test.drop('>=50K', axis=1)\n",
    "y_train = df_train['>=50K']\n",
    "y_test = df_test['>=50K']   \n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&gt;=50K</th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>native-country</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38113</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>151856</td>\n",
       "      <td>40</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39214</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>87584</td>\n",
       "      <td>25</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>White</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Female</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44248</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>31</td>\n",
       "      <td>6849</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>220669</td>\n",
       "      <td>40</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>White</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Female</td>\n",
       "      <td>Local-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>171355</td>\n",
       "      <td>20</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26724</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>148626</td>\n",
       "      <td>40</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        >=50K  age  capital-gain  capital-loss  education  education-num  \\\n",
       "38113  <=50K.   41             0             0    HS-grad              9   \n",
       "39214  <=50K.   57             0             0  Doctorate             16   \n",
       "44248  <=50K.   31          6849             0  Bachelors             13   \n",
       "10283   <=50K   55             0             0  Assoc-voc             11   \n",
       "26724   <=50K   59             0             0       10th              6   \n",
       "\n",
       "       fnlwgt  hours-per-week      marital-status native-country  \\\n",
       "38113  151856              40  Married-civ-spouse  United-States   \n",
       "39214   87584              25            Divorced  United-States   \n",
       "44248  220669              40       Never-married  United-States   \n",
       "10283  171355              20  Married-civ-spouse  United-States   \n",
       "26724  148626              40  Married-civ-spouse  United-States   \n",
       "\n",
       "              occupation   race   relationship     sex         workclass  \n",
       "38113    Protective-serv  White        Husband    Male           Private  \n",
       "39214     Prof-specialty  White  Not-in-family  Female  Self-emp-not-inc  \n",
       "44248     Prof-specialty  White      Own-child  Female         Local-gov  \n",
       "10283  Machine-op-inspct  White        Husband    Male           Private  \n",
       "26724    Farming-fishing  White        Husband    Male  Self-emp-not-inc  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How shall we prepare our data for modeling?\n",
    "* Cleaning\n",
    "* Missing data\n",
    "* Scale numeric features\n",
    "* Encode categorical features\n",
    "* Trasformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why should we automate data preparation?\n",
    "* Efficiency\n",
    "* Controlled Experimentation\n",
    "* Reproducibility in Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Data Preparation Pipelines\n",
    "Learning resources:\n",
    "* [Sklearn documentation](https://scikit-learn.org/stable/data_transforms.html) - Dataset transformations\n",
    "* [Hands-On Machine Learning with Scikit-Learn & TensorFlow / Aurelien Geron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) - Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn interface design principles\n",
    "Sklearn objects share a consistent interface.\n",
    "* **Estimators** include any object that can estimate parameter/s base on a dataset. Estimation is performed by the ```fit()```method, which recieves a dataset as an argument (plus a labels dataset in case of supervised learning). \n",
    "    -     A **hyperparameter** is any parameter that guides the estimation. Hyperparameters are directly accessible via public instance variables. For example, we can access logistic regression's penalty hyperparameter using ```log_reg.penalty```.\n",
    "    -     An estimator's **learned parameters** can be accessed via public instance variables with an underscore suffix (e.g. ```log_reg.coef_```).\n",
    "* **Predictors** are estimators that are capable of making predictions, using the ```predict()```method.\n",
    "* **Transformers** are estimators that can transform a dataset, typically based on the learned parameters. Transformation is performed by the ```transform()```method, , which recieves the dataset to trasform as an argument and returns the transformed dataset. All transformers have a convenience ```fit_transform()``` method that is equivalent to calling ```fit()``` and then ```transform()```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of scaled data:\n",
      " [[ 0.16988957 -0.35849554 -0.41755169 -0.14580568 -0.21438168 -0.03499028]\n",
      " [ 1.336995   -0.96551754  2.2946621  -0.14580568 -0.21438168 -1.24844225]\n",
      " [-0.55955132  0.29141429  1.13228476  0.75816992 -0.21438168 -0.03499028]]\n"
     ]
    }
   ],
   "source": [
    "# Sklearn has a rich library of built-in transformers. Here is the standard scaler: \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "# During the .fit() method, the scaler learns the mean and the variance in the train data\n",
    "scaler.fit(X_train[num_features]) \n",
    "# The .transform() method normalizes the data using to the learned parameters\n",
    "train_scaled = scaler.transform(X_train[num_features])\n",
    "print(\"Beginning of scaled data:\\n\", train_scaled[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.86709618e+01 1.89813810e+05 1.00776665e+01 1.10470137e+03\n",
      " 8.51810215e+01 4.04325298e+01]\n",
      "\n",
      "The mean age is 38.67\n"
     ]
    }
   ],
   "source": [
    "# Here is how we access the learned parameters:\n",
    "print(scaler.mean_)\n",
    "print('\\nThe mean age is %.2f' % scaler.mean_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of scaled test data:\n",
      " [[-1.21604812  0.07871292 -0.03009258 -0.14580568 -0.21438168  0.7739777 ]\n",
      " [ 1.55582727 -0.65782259  1.13228476 -0.14580568 -0.21438168 -0.03499028]\n",
      " [ 0.46166593  0.65732562  1.90720299 13.05271322 -0.21438168  0.7739777 ]]\n"
     ]
    }
   ],
   "source": [
    "# The trained transformer can be used to process unseen data\n",
    "test_scaled = scaler.transform(df_test[num_features])\n",
    "print(\"Beginning of scaled test data:\\n\", test_scaled[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of scaled data:\n",
      " [[ 0.16988957 -0.35849554 -0.41755169 -0.14580568 -0.21438168 -0.03499028]\n",
      " [ 1.336995   -0.96551754  2.2946621  -0.14580568 -0.21438168 -1.24844225]\n",
      " [-0.55955132  0.29141429  1.13228476  0.75816992 -0.21438168 -0.03499028]]\n"
     ]
    }
   ],
   "source": [
    "# An alternative, more concise version:\n",
    "train_scaled = scaler.fit_transform(X_train[num_features])\n",
    "print(\"Beginning of scaled data:\\n\", train_scaled[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily write our own transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MyStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # We must have an __init__ method - the constructor of the object. \n",
    "        # This is where we would initialize any hyperparameters. \n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        # This is where we learn our learned parameters - here the mean and std. \n",
    "        # We must include a 'y' argument, but we don't have to use it.\n",
    "        # fit() always return 'self' - a reference to the transformer.\n",
    "        self.mean_ = np.mean(X) \n",
    "        self.std_ = np.std(X)     \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Transforms the data and returns the transformed dataset.\n",
    "        X_transformed = X.copy()\n",
    "        for column in X:\n",
    "            X_transformed[column] = (X[column] - self.mean_[column]) / self.std_[column]\n",
    "        return X_transformed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of custom scaled data:\n",
      " [[ 0.16988957 -0.35849554 -0.41755169 -0.14580568 -0.21438168 -0.03499028]\n",
      " [ 1.336995   -0.96551754  2.2946621  -0.14580568 -0.21438168 -1.24844225]\n",
      " [-0.55955132  0.29141429  1.13228476  0.75816992 -0.21438168 -0.03499028]]\n",
      "\n",
      "Beginning of sklearn scaled data:\n",
      " [[ 0.16988957 -0.35849554 -0.41755169 -0.14580568 -0.21438168 -0.03499028]\n",
      " [ 1.336995   -0.96551754  2.2946621  -0.14580568 -0.21438168 -1.24844225]\n",
      " [-0.55955132  0.29141429  1.13228476  0.75816992 -0.21438168 -0.03499028]]\n"
     ]
    }
   ],
   "source": [
    "# Hey - the it looks just the same!\n",
    "my_scaler = MyStandardScaler()\n",
    "my_train_scaled = my_scaler.fit_transform(X_train[num_features])\n",
    "print(\"Beginning of custom scaled data:\\n\", my_train_scaled[:3])\n",
    "print(\"\\nBeginning of sklearn scaled data:\\n\", train_scaled[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36631, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now what if we want to add another transformer, say polynomial features?\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "scaler = StandardScaler()\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# Asimple syntax for initializing a pipeline\n",
    "num_pipeline = Pipeline([('PolynomialFeatures', poly), ('StandardScaler', scaler)])\n",
    "\n",
    "# The pipeline object is just another transformer\n",
    "num_train_prepared = num_pipeline.fit_transform(df_train[num_features])\n",
    "num_train_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('PolynomialFeatures',\n",
       "                 PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('StandardScaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can easily see the definition of the pipeline\n",
    "num_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 3.86709618e+01, 1.89813810e+05, 1.00776665e+01,\n",
       "       1.10470137e+03, 8.51810215e+01, 4.04325298e+01, 1.68338353e+03,\n",
       "       7.22755188e+06, 3.90800551e+02, 5.09331961e+04, 3.59402132e+03,\n",
       "       1.57505403e+03, 4.72400351e+10, 1.90363423e+06, 2.08697379e+08,\n",
       "       1.60906021e+07, 7.66291370e+06, 1.08220496e+02, 1.35913009e+04,\n",
       "       9.44393328e+02, 4.12171712e+02, 5.86242014e+07, 0.00000000e+00,\n",
       "       5.25411236e+04, 1.65129703e+05, 3.70308722e+03, 1.78759439e+03])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access a pipeline learned parameters through the steps attribute:\n",
    "num_pipeline.steps[1][1].mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('PolynomialFeatures',\n",
       "   PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                      order='C')),\n",
       "  ('StandardScaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'verbose': False,\n",
       " 'PolynomialFeatures': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'StandardScaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'PolynomialFeatures__degree': 2,\n",
       " 'PolynomialFeatures__include_bias': True,\n",
       " 'PolynomialFeatures__interaction_only': False,\n",
       " 'PolynomialFeatures__order': 'C',\n",
       " 'StandardScaler__copy': True,\n",
       " 'StandardScaler__with_mean': True,\n",
       " 'StandardScaler__with_std': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we can access parameters of transformers in a pipeline using the methods\n",
    "# get_params/set_params. A parameter is referenced using the estimator \n",
    "#  name + '__' + parameter name.\n",
    "num_pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the LabelEncoder to encode the targets \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_train = y_train.str.strip('.')\n",
    "y_test = y_test.str.strip('.')\n",
    "\n",
    "le = LabelEncoder() \n",
    "y_train_prepared = le.fit_transform(y_train)\n",
    "y_train_prepared[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36631, 107) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.16988957, -0.35849554, -0.41755169, -0.14580568, -0.21438168,\n",
       "        -0.03499028,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use column transformers to match different features with different pipelines\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "cat_features = X_train.columns.drop(num_features)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "column_transformer = ColumnTransformer([('Standard Scaler', scaler, num_features), \n",
    "                                        ('OneHotEncoder', encoder, cat_features)],\n",
    "                                      sparse_threshold=0)\n",
    "\n",
    "X_train_prepared = column_transformer.fit_transform(X_train)\n",
    "print(X_train_prepared.shape, '\\n')\n",
    "X_train_prepared[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36631, 129)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By combining pipelines and column transformers, we can create any data-preparation \n",
    "# configuration we want.\n",
    "column_transformer = ColumnTransformer([('Numeric pipeline', num_pipeline, num_features), \n",
    "                                        ('OneHotEncoder', encoder, cat_features)],\n",
    "                                      sparse_threshold=0)\n",
    "X_train_prepared = column_transformer.fit_transform(X_train)\n",
    "X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pro's trick: cross-validated pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard scaler score: (CV score=0.852):\n",
      "Min-max scaler score: (CV score=0.850):\n"
     ]
    }
   ],
   "source": [
    "# Let's use cross validation to compare StandardScaler and MinMaxScaler.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scaler = None # We will assign the actual scaler to this placeholder variable.\n",
    "lr = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "column_transformer = ColumnTransformer([('Scaler', scaler, num_features), \n",
    "                                 ('OneHotEncoder', encoder, cat_features)])\n",
    "\n",
    "cv_pipeline = Pipeline([('Transformer', column_transformer), \n",
    "                        ('Regressor', lr)])\n",
    "# Set paramaeter to test using cross validation\n",
    "param_grid = {\n",
    "    'Transformer__Scaler': [std_scaler, min_max_scaler],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(cv_pipeline, param_grid, cv=5, return_train_score=False)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Standard scaler score: (CV score=%0.3f):\" % grid_search.cv_results_['mean_test_score'][0])\n",
    "print(\"Min-max scaler score: (CV score=%0.3f):\" % grid_search.cv_results_['mean_test_score'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Pipeline for our Project\n",
    "## The plan\n",
    "Here are some decisions on how to process the data:\n",
    "1. **Data cleaning** - we need to strip the dot from the end of the target.\n",
    "2. **Missing values** - leave '?' as valid categories.\n",
    "3. **Feature selection** - we will remove `education` and only use `education-num`.\n",
    "4. **Scaling** numeric features\n",
    "5. **Encoding** categorical features\n",
    "6. **Combining categories**: combining very small categories with bigger ones:\n",
    "    * For `marital-status`, we will combine `Married-AF-spouse` with `Married-civ-spouse`.\n",
    "    * For `workclass`, we will combine `Without-pay` and `Never-worked` with `?`.\n",
    "    * For `occupation`, we will combine `Armed-Forces` with `Prof-specialty`. \n",
    "6. **Feature creation and transformation for 'native-country'**: in order to deal with the high cardinality, we will build a target encoder that will substitute a category by its (regularized) positive rate. We will also create categorical variables for Continents (to capture interactions).\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    27824\n",
       ">50K      8807\n",
       "Name: >=50K, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning: you will develop your own transformer during homework. For now, I am importing a version I created.\n",
    "from lesson11 import CharacterStripper\n",
    "\n",
    "character_stripper = CharacterStripper(character_to_strip='.')\n",
    "y_train_prepared = character_stripper.fit_transform(y_train)\n",
    "y_train_prepared.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that changes category names according to specified rules\n",
    "class CategoryReviser(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer revises categories according to a dictionary with rules '''\n",
    "    def __init__(self, cat_change_rules={}):\n",
    "        self.cat_change_rules = cat_change_rules\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feature in self.cat_change_rules:\n",
    "            for cat in self.cat_change_rules[feature]:\n",
    "                X_transformed.loc[X[feature]==cat, feature] = self.cat_change_rules[feature][cat]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_change_rules = {'marital-status':{'Married-AF-spouse':'Married', 'Married-civ-spouse':'Married'}, \n",
    "                'workclass':{'Without-pay':'?', 'Never-worked':'?'},\n",
    "                'occupation':{'Armed-Forces':'Prof-specialty'}}\n",
    "\n",
    "category_reviser = CategoryReviser(cat_change_rules=cat_change_rules)\n",
    "X_train_prepared = category_reviser.fit_transform(X_train)\n",
    "X_train_prepared['marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "1. Ealier, we stripped manually the dot from the end of some values in the target feature. You task is to create a custom transfomer  - `CharacterStripper` - which does it automatically and can work on production data. The example below shows the expected behavior of the `CharacterStripper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K     18490\n",
       "<=50K.     9334\n",
       ">50K       5923\n",
       ">50K.      2884\n",
       "Name: >=50K, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's un-strip the dots from the end of the target feature\n",
    "y_train = df_train['>=50K']\n",
    "y_test = df_test['>=50K']   \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    27824\n",
       ">50K      8807\n",
       "Name: >=50K, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Develop a character stripper that works like this:\n",
    "from lesson11 import CharacterStripper\n",
    "\n",
    "character_stripper = CharacterStripper(character_to_strip='.')\n",
    "y_train_prepared = character_stripper.fit_transform(y_train)\n",
    "y_train_prepared.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build a TargetEncoder transformer that replaces a category with the positive rate for that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>native-country</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>workclass</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38113</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>151856</td>\n",
       "      <td>40</td>\n",
       "      <td>Married</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39214</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>87584</td>\n",
       "      <td>25</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>White</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Female</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44248</th>\n",
       "      <td>31</td>\n",
       "      <td>6849</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>220669</td>\n",
       "      <td>40</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>White</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Female</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>171355</td>\n",
       "      <td>20</td>\n",
       "      <td>Married</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26724</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>148626</td>\n",
       "      <td>40</td>\n",
       "      <td>Married</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  capital-gain  capital-loss  education  education-num  fnlwgt  \\\n",
       "38113   41             0             0    HS-grad              9  151856   \n",
       "39214   57             0             0  Doctorate             16   87584   \n",
       "44248   31          6849             0  Bachelors             13  220669   \n",
       "10283   55             0             0  Assoc-voc             11  171355   \n",
       "26724   59             0             0       10th              6  148626   \n",
       "\n",
       "       hours-per-week marital-status native-country         occupation   race  \\\n",
       "38113              40        Married  United-States    Protective-serv  White   \n",
       "39214              25       Divorced  United-States     Prof-specialty  White   \n",
       "44248              40  Never-married  United-States     Prof-specialty  White   \n",
       "10283              20        Married  United-States  Machine-op-inspct  White   \n",
       "26724              40        Married  United-States    Farming-fishing  White   \n",
       "\n",
       "        relationship     sex         workclass  target  \n",
       "38113        Husband    Male           Private       0  \n",
       "39214  Not-in-family  Female  Self-emp-not-inc       0  \n",
       "44248      Own-child  Female         Local-gov       0  \n",
       "10283        Husband    Male           Private       0  \n",
       "26724        Husband    Male  Self-emp-not-inc       0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38113    2,075,872\n",
       "39214    1,197,273\n",
       "44248    3,016,545\n",
       "10283    2,342,423\n",
       "26724    2,031,717\n",
       "Name: fnlwgt, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_train.copy()\n",
    "df_test['fnlwgt'] = df_test['fnlwgt'] * 13.67\n",
    "df_test['fnlwgt'] = df_test['fnlwgt'].apply(lambda x : '{0:,.0f}'.format(x))\n",
    "df_test.head().to_csv('test.csv')\n",
    "df_test['fnlwgt'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head().to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
