{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "\n",
      "Pandas info\n",
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "# Which versions are installed?\n",
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"\\nPandas info\")\n",
    "print (pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing Basics\n",
    "## The assert statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "the variable b should have a value of at least 5 , but it is only 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-df863e7f7537>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'the variable b should have a value of at least 5 , but it is only %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: the variable b should have a value of at least 5 , but it is only 3"
     ]
    }
   ],
   "source": [
    "# We use the assert statement to identify bugs in our programs\n",
    "b = 3\n",
    "\n",
    "assert b > 5, 'the variable b should have a value of at least 5 , but it is only %s' % b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we use the assert statement to validate that our data was successfully loaded\n",
    "\n",
    "def get_data():\n",
    "    df_1 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True)\n",
    "    df_2 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True, skiprows=1)\n",
    "    df_combined = df_1.append(df_2, ignore_index=True, sort=True)\n",
    "    \n",
    "    # Check this out -  \n",
    "    assert df_combined.shape == (48842, 15), 'Expected data frame shape:%s; actual:%s' % ((48842, 16), df_combined.shape)\n",
    "\n",
    "    X = df_combined.drop(columns=['>=50K'])\n",
    "    y = df_combined['>=50K']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit testing with pytest\n",
    "[pytest](https://docs.pytest.org/en/latest/) is comprehensive Python testing tool that helps write better programs.\n",
    "\n",
    "Here is Nana and Alice's presentation [Unit Testing for Data Science](https://my.metlife.com/:p:/r/sites/AnalyticsCommunity/_layouts/15/Doc.aspx?sourcedoc=%7B01975490-24A1-435D-A104-7E8EE5DC8E6B%7D&file=unit_test_framework_launch_v3.pptx&action=edit&mobileredirect=true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterStripper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, character_to_strip='.'):\n",
    "        self.character_to_strip = character_to_strip\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X\n",
    "        X_transformed = X_transformed.str.strip(self.character_to_strip)\n",
    "        return X_transformed       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_normal_input():\n",
    "    data = pd.Series(['a.', 'b', 'c...', 'd'])\n",
    "    char_stripper = CharacterStripper('.')\n",
    "    expected = pd.Series(['a', 'b', 'c', 'd'])\n",
    "    actual = char_stripper.fit_transform(data)\n",
    "    pd.testing.assert_series_equal(expected, actual)\n",
    "    \n",
    "test_on_normal_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run the test through pytest, we need to:\n",
    "1. Install it in our environment using Anaconda ([you can search online how to do that](https://www.google.com/search?q=anaconda+install+pytest&rlz=1C1GCEU_enUS837US837&oq=anaconda+install+pytest)).\n",
    "2. Have your directories properly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.4, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\tyifat\\Workspace\\python-for-dna\\Season 2\\lesson 12\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_custom_transformers.py .                                      [100%]\n",
      "\n",
      "============================== 1 passed in 1.38s ==============================\n"
     ]
    }
   ],
   "source": [
    "# '!' allows you to run terminal commends from Jupyter notebook\n",
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Driven Development (TDD)\n",
    "TDD is a software development process in which tests are developed before the code that delivers the required functionality. A typical TDD cycle looks something like this:\n",
    "1. Define requirements\n",
    "2. Turn requirements into tests\n",
    "3. Run all tests and see if the new test fails\n",
    "4. Write/improve the code so that tests pass\n",
    "5. Run tests\n",
    "6. Refactor code (that is, cleanup, improve).\n",
    "7. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCountry2ContinentConverter():\n",
    "    def test_on_normal_data_1(self):\n",
    "        data = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'China', 'India', 'U.S.', 'Mexico']})\n",
    "        conversion_rules = {'U.S.':'America',\n",
    "                           'Mexico':'America',\n",
    "                           'China':'Asia',\n",
    "                           'India':'Asia'}\n",
    "        country_2_continent = Country2ContinentConverter(country_col='country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=conversion_rules)\n",
    "        expected = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'China', 'India', 'U.S.', 'Mexico'],\n",
    "                             'continent':['America', 'Asia', 'Asia', 'America', 'America']})\n",
    "        actual = country_2_continent.fit_transform(data)\n",
    "        pd.testing.assert_frame_equal(expected, actual)\n",
    "\n",
    "    def test_on_normal_data_2(self):\n",
    "        pass\n",
    "    \n",
    "    def test_on_missing_value(self):\n",
    "        data = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', np.nan, 'India', 'U.S.', 'Mexico']})\n",
    "        conversion_rules = {'U.S.':'America',\n",
    "                           'Mexico':'America',\n",
    "                           'China':'Asia',\n",
    "                           'India':'Asia'}\n",
    "        country_2_continent = Country2ContinentConverter(country_col='country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=conversion_rules)\n",
    "        expected = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', np.nan, 'India', 'U.S.', 'Mexico'],\n",
    "                             'continent':['America', '', 'Asia', 'America', 'America']})\n",
    "        actual = country_2_continent.fit_transform(data)\n",
    "        pd.testing.assert_frame_equal(expected, actual)\n",
    "    \n",
    "    def test_on_unknown_value(self):\n",
    "        data = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'Argentina', 'India', 'U.S.', 'Mexico']})\n",
    "        conversion_rules = {'U.S.':'America',\n",
    "                           'Mexico':'America',\n",
    "                           'China':'Asia',\n",
    "                           'India':'Asia'}\n",
    "        country_2_continent = Country2ContinentConverter(country_col='country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=conversion_rules)\n",
    "        expected = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'Argentina', 'India', 'U.S.', 'Mexico'],\n",
    "                             'continent':['America', '', 'Asia', 'America', 'America']})\n",
    "        actual = country_2_continent.fit_transform(data)\n",
    "        pd.testing.assert_frame_equal(expected, actual)\n",
    "    \n",
    "    def test_on_missing_column(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that changes category names according to specified rules\n",
    "class Country2ContinentConverter(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer revises categories according to a dictionary with rules '''\n",
    "    def __init__(self, country_col='native-country', continent_col='continent', conversion_rules={}):\n",
    "        self.country_col = country_col\n",
    "        self.continent_col = continent_col\n",
    "        self.conversion_rules = conversion_rules\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.continent_col] = ''\n",
    "        for country in self.conversion_rules:\n",
    "            X_transformed.loc[X[self.country_col]==country, self.continent_col] = self.conversion_rules[country]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country_2_continent = TestCountry2ContinentConverter()\n",
    "test_country_2_continent.test_on_normal_data_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country_2_continent.test_on_missing_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country_2_continent.test_on_unknown_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country_2_continent.test_on_missing_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.4, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\tyifat\\Workspace\\python-for-dna\\Season 2\\lesson 12\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_custom_transformers.py .                                      [100%]\n",
      "\n",
      "============================== 1 passed in 1.42s ==============================\n"
     ]
    }
   ],
   "source": [
    "# We have to add the transformer and the test to our scripts before we can run them with pytest\n",
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing our Data-Prep Pipeline\n",
    "## More custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that changes category names according to specified rules\n",
    "class CategoryReviser(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer revises categories according to a dictionary with rules '''\n",
    "    def __init__(self, cat_change_rules={}):\n",
    "        self.cat_change_rules = cat_change_rules\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feature in self.cat_change_rules:\n",
    "            for cat in self.cat_change_rules[feature]:\n",
    "                X_transformed.loc[X[feature]==cat, feature] = self.cat_change_rules[feature][cat]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Married                  16901\n",
       "Never-married            12010\n",
       "Divorced                  4970\n",
       "Separated                 1147\n",
       "Widowed                   1132\n",
       "Married-spouse-absent      471\n",
       "Name: marital-status, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_change_rules = {'marital-status':{'Married-AF-spouse':'Married', 'Married-civ-spouse':'Married'}, \n",
    "                    'workclass':{'Without-pay':'?', 'Never-worked':'?'},\n",
    "                    'occupation':{'Armed-Forces':'Prof-specialty'}}\n",
    "\n",
    "category_reviser = CategoryReviser(cat_change_rules=cat_change_rules)\n",
    "X_train_prepared = category_reviser.fit_transform(X_train)\n",
    "X_train_prepared['marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target encoder replaces a category with the positive rate for that category\n",
    "class BasicTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        self.mapping = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_y = X.copy()\n",
    "        X_y['target'] = y\n",
    "        for feat in self.features:\n",
    "            cat_positive_rates = {}\n",
    "            for feat in self.features:\n",
    "                self.mapping[feat] = {}\n",
    "                positive_rates = X_y.groupby(feat)['target'].mean()\n",
    "                for cat in X_y[feat].unique():\n",
    "                    self.mapping[feat][cat] = positive_rates.loc[cat]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feat in self.mapping:\n",
    "            for cat in self.mapping[feat]:\n",
    "                X_transformed.loc[X[feat]==cat, feat] = self.mapping[feat][cat]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hong                          20\n",
       "Thailand                      19\n",
       "Scotland                      19\n",
       "Yugoslavia                    18\n",
       "Trinadad&Tobago               17\n",
       "Outlying-US(Guam-USVI-etc)    17\n",
       "Honduras                      16\n",
       "Laos                          16\n",
       "Hungary                       12\n",
       "Holand-Netherlands             1\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['native-country'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125000    32\n",
       "0.103448    29\n",
       "0.344828    29\n",
       "0.461538    26\n",
       "0.380952    21\n",
       "0.250000    20\n",
       "0.105263    19\n",
       "0.210526    19\n",
       "0.388889    18\n",
       "0.000000     1\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from lesson11 import CharacterStripper\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# We cannot use LabelEncoder inside a pipeline\n",
    "character_stripper = CharacterStripper(character_to_strip='.')\n",
    "y_stripped = character_stripper.fit_transform(y_train)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_prepared = label_encoder.fit_transform(y_stripped)\n",
    "\n",
    "target_encoder = BasicTargetEncoder(['native-country'])\n",
    "X_prepared = target_encoder.fit_transform(X_train, y_train_prepared)\n",
    "X_prepared['native-country'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we regularize the target encodeing by taking the weighted average of the positive rate for the specific category\n",
    "# and the positive rate for the entire dataset. The argument 'reg_weight' controls the weighting.\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, reg_weight=20):\n",
    "        self.features = features\n",
    "        self.reg_weight = reg_weight\n",
    "        self.mapping = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_positive_rate = y.mean()\n",
    "        X_y = X.copy()\n",
    "        X_y['target'] = y\n",
    "        for feat in self.features:\n",
    "            cat_positive_rates = {}\n",
    "            for feat in self.features:\n",
    "                self.mapping[feat] = {}\n",
    "                positive_rates = X_y.groupby(feat)['target'].mean()\n",
    "                value_counts = X_y[feat].value_counts()\n",
    "                for cat in X_y[feat].unique():\n",
    "                    n = value_counts.loc[cat]\n",
    "                    rate = positive_rates.loc[cat]\n",
    "                    regularized_rate = (rate * n + X_positive_rate * self.reg_weight) / (n + self.reg_weight)\n",
    "                    self.mapping[feat][cat] = regularized_rate\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feat in self.mapping:\n",
    "            for cat in self.mapping[feat]:\n",
    "                X_transformed.loc[X[feat]==cat, feat] = self.mapping[feat][cat]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.365699    26\n",
       "0.312735    21\n",
       "0.245554    20\n",
       "0.174927    19\n",
       "0.226209    19\n",
       "0.311109    18\n",
       "0.184382    17\n",
       "0.157355    17\n",
       "0.275692    12\n",
       "0.229626     1\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoder = TargetEncoder(['native-country'])\n",
    "X_prepared = target_encoder.fit_transform(X_train, y_train_prepared)\n",
    "X_prepared['native-country'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularizing the script as functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df_1 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True)\n",
    "    df_2 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True, skiprows=1)\n",
    "    df_combined = df_1.append(df_2, ignore_index=True, sort=True)\n",
    "    X = df_combined.drop(columns=['>=50K'])\n",
    "    y = df_combined['>=50K']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_y(y):\n",
    "    character_stripper = CharacterStripper(character_to_strip='.')\n",
    "    y_stripped = character_stripper.fit_transform(y_train)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_prepared = label_encoder.fit_transform(y_stripped)\n",
    "    return y_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_X_pipeline():\n",
    "    num_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',]\n",
    "    cat_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'continent']\n",
    "\n",
    "    cat_change_rules = {'marital-status':{'Married-AF-spouse':'Married', 'Married-civ-spouse':'Married'}, \n",
    "                        'workclass':{'Without-pay':'?', 'Never-worked':'?'},\n",
    "                        'occupation':{'Armed-Forces':'Prof-specialty'}}\n",
    "    country_2_contonent_rules = {'United-States':'N-America',\n",
    "                         'Germany':'Europe',\n",
    "                         'Mexico':'LatAm',\n",
    "                         'Scotland':'Europe',\n",
    "                         'Peru':'LatAm',\n",
    "                         'Honduras':'LatAm',\n",
    "                         'Ecuador':'LatAm',\n",
    "                         'Poland':'Europe',\n",
    "                         'China':'Asia',\n",
    "                         'Nicaragua':'LatAm',\n",
    "                         'India':'Asia',\n",
    "                         'Philippines':'Asia',\n",
    "                         'Iran':'Asia',\n",
    "                         'Japan':'Asia',\n",
    "                         'Vietnam':'Asia',\n",
    "                         'Dominican-Republic':'LatAm',\n",
    "                         'Ireland':'Europe',\n",
    "                         'Laos':'Asia',\n",
    "                         'Jamaica':'LatAm',\n",
    "                         'England':'Europe',\n",
    "                         'Hong':'Asia',\n",
    "                         'Puerto-Rico':'LatAm',\n",
    "                         'Cuba':'LatAm',\n",
    "                         'Haiti':'LatAm',\n",
    "                         'Guatemala':'LatAm',\n",
    "                         'El-Salvador':'LatAm',\n",
    "                         'Columbia':'LatAm',\n",
    "                         'Italy':'Europe',\n",
    "                         'Taiwan':'Asia',\n",
    "                         'Canada':'N-America',\n",
    "                         'Portugal':'Europe',\n",
    "                         'Thailand':'Asia',\n",
    "                         'Cambodia':'Asia',\n",
    "                         'France':'Europe',\n",
    "                         'Greece':'Europe',\n",
    "                         'Trinadad&Tobago':'LatAm',\n",
    "                         'Yugoslavia':'Europe',\n",
    "                         'Hungary':'Europe',\n",
    "                         'Holand-Netherlands':'Europe',\n",
    "                        }\n",
    "\n",
    "    # Create and parametatrize data transformers\n",
    "    scaler = StandardScaler()\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    category_reviser = CategoryReviser(cat_change_rules=cat_change_rules)\n",
    "    country_2_continent = Country2ContinentConverter(country_col='native-country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=country_2_contonent_rules)\n",
    "    target_encoder = TargetEncoder(['native-country'])\n",
    "\n",
    "    column_transformer = ColumnTransformer([('Scaler', scaler, num_features), \n",
    "                                            ('One Hot Encoder', one_hot_encoder, cat_features)])\n",
    "\n",
    "    # Define the data transformation pipeline\n",
    "    X_pipeline = Pipeline([('Category Reviser', category_reviser), \n",
    "                           ('Country to Continent', country_2_continent), \n",
    "                           ('Target Encoder', target_encoder), \n",
    "                           ('ColumnTransformer', column_transformer)])\n",
    "    return X_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36631, 52), (36631,), (12211, 52), (36631,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_data()\n",
    "y_train_prepared = preprocess_y(y_train)\n",
    "y_test_prepared = preprocess_y(y_test)\n",
    "X_pipeline = build_X_pipeline()\n",
    "X_train_prepared = X_pipeline.fit_transform(X_train, y_train_prepared)\n",
    "X_test_prepared = X_pipeline.transform(X_test)\n",
    "\n",
    "X_train_prepared.shape, y_train_prepared.shape, X_test_prepared.shape, y_test_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "Pick one of the custom transformenrs and write a couple of tests for it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
