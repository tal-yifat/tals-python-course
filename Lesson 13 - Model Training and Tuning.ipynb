{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "\n",
      "Pandas info\n",
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "# Which versions are installed?\n",
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"\\nPandas info\")\n",
    "print (pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Prep Pipeline from Previous Lessons\n",
    "## Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that changes category names according to specified rules\n",
    "class Country2ContinentConverter(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer revises categories according to a dictionary with rules '''\n",
    "    def __init__(self, country_col='native-country', continent_col='continent', conversion_rules={}):\n",
    "        self.country_col = country_col\n",
    "        self.continent_col = continent_col\n",
    "        self.conversion_rules = conversion_rules\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.continent_col] = ''\n",
    "        for country in self.conversion_rules:\n",
    "            X_transformed.loc[X[self.country_col]==country, self.continent_col] = self.conversion_rules[country]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that changes category names according to specified rules\n",
    "class CategoryReviser(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer revises categories according to a dictionary with rules '''\n",
    "    def __init__(self, cat_change_rules={}):\n",
    "        self.cat_change_rules = cat_change_rules\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feature in self.cat_change_rules:\n",
    "            for cat in self.cat_change_rules[feature]:\n",
    "                X_transformed.loc[X[feature]==cat, feature] = self.cat_change_rules[feature][cat]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we regularize the target encodeing by taking the weighted average of the positive rate for the specific category\n",
    "# and the positive rate for the entire dataset. The argument 'reg_weight' controls the weighting.\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer replaces a category with the regularized positive rate for that category '''\n",
    "    def __init__(self, features, reg_weight=20):\n",
    "        self.features = features\n",
    "        self.reg_weight = reg_weight\n",
    "        self.mapping = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X_positive_rate = y.mean()\n",
    "        X_y = X.copy()\n",
    "        X_y['target'] = y\n",
    "        for feat in self.features:\n",
    "            cat_positive_rates = {}\n",
    "            for feat in self.features:\n",
    "                self.mapping[feat] = {}\n",
    "                positive_rates = X_y.groupby(feat)['target'].mean()\n",
    "                value_counts = X_y[feat].value_counts()\n",
    "                for cat in X_y[feat].unique():\n",
    "                    n = value_counts.loc[cat]\n",
    "                    rate = positive_rates.loc[cat]\n",
    "                    regularized_rate = (rate * n + self.X_positive_rate * self.reg_weight) / (n + self.reg_weight)\n",
    "                    self.mapping[feat][cat] = regularized_rate\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feat in self.mapping:\n",
    "            for cat in X[feat].unique():\n",
    "                try:\n",
    "                    # If the category was mapped during fitting, change it. \n",
    "                    X_transformed.loc[X[feat]==cat, feat] = self.mapping[feat][cat]\n",
    "                except: \n",
    "                    # If the category is unknown, replace it with the mean positive rate\n",
    "                    X_transformed.loc[X[feat]==cat, feat] = self.X_positive_rate\n",
    "                    \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterStripper(BaseEstimator, TransformerMixin):\n",
    "    ''' Strip a charapter from the end of a string'''\n",
    "    def __init__(self, character_to_strip='.'):\n",
    "        self.character_to_strip = character_to_strip\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X\n",
    "        X_transformed = X_transformed.str.strip(self.character_to_strip)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-prep Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(columns_to_drop=None):\n",
    "    ''' Downloan the data, and create train and test sets. '''\n",
    "    df_1 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True)\n",
    "    df_2 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True, skiprows=1)\n",
    "    df_combined = df_1.append(df_2, ignore_index=True, sort=True)\n",
    "    if columns_to_drop:\n",
    "        df_combined = df_combined.drop(columns=columns_to_drop)\n",
    "    X = df_combined.drop(columns=['>=50K'])\n",
    "    y = df_combined['>=50K']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_y(y):\n",
    "    ''' Remove dots from the end and encode the target feature. '''\n",
    "    character_stripper = CharacterStripper(character_to_strip='.')\n",
    "    y_stripped = character_stripper.fit_transform(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_prepared = label_encoder.fit_transform(y_stripped)\n",
    "    return y_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_X_pipeline_full(predictor=None):\n",
    "    ''' Build pipeline with all the features. '''\n",
    "    num_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',]\n",
    "    cat_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'continent']\n",
    "\n",
    "    cat_change_rules = {'marital-status':{'Married-AF-spouse':'Married', 'Married-civ-spouse':'Married'}, \n",
    "                        'workclass':{'Without-pay':'?', 'Never-worked':'?'},\n",
    "                        'occupation':{'Armed-Forces':'Prof-specialty'}}\n",
    "    country_2_contonent_rules = {'United-States':'N-America',\n",
    "                         'Germany':'Europe',\n",
    "                         'Mexico':'LatAm',\n",
    "                         'Scotland':'Europe',\n",
    "                         'Peru':'LatAm',\n",
    "                         'Honduras':'LatAm',\n",
    "                         'Ecuador':'LatAm',\n",
    "                         'Poland':'Europe',\n",
    "                         'China':'Asia',\n",
    "                         'Nicaragua':'LatAm',\n",
    "                         'India':'Asia',\n",
    "                         'Philippines':'Asia',\n",
    "                         'Iran':'Asia',\n",
    "                         'Japan':'Asia',\n",
    "                         'Vietnam':'Asia',\n",
    "                         'Dominican-Republic':'LatAm',\n",
    "                         'Ireland':'Europe',\n",
    "                         'Laos':'Asia',\n",
    "                         'Jamaica':'LatAm',\n",
    "                         'England':'Europe',\n",
    "                         'Hong':'Asia',\n",
    "                         'Puerto-Rico':'LatAm',\n",
    "                         'Cuba':'LatAm',\n",
    "                         'Haiti':'LatAm',\n",
    "                         'Guatemala':'LatAm',\n",
    "                         'El-Salvador':'LatAm',\n",
    "                         'Columbia':'LatAm',\n",
    "                         'Italy':'Europe',\n",
    "                         'Taiwan':'Asia',\n",
    "                         'Canada':'N-America',\n",
    "                         'Portugal':'Europe',\n",
    "                         'Thailand':'Asia',\n",
    "                         'Cambodia':'Asia',\n",
    "                         'France':'Europe',\n",
    "                         'Greece':'Europe',\n",
    "                         'Trinadad&Tobago':'LatAm',\n",
    "                         'Yugoslavia':'Europe',\n",
    "                         'Hungary':'Europe',\n",
    "                         'Holand-Netherlands':'Europe',\n",
    "                        }\n",
    "\n",
    "    # Create and parametatrize data transformers\n",
    "    scaler = StandardScaler()\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    category_reviser = CategoryReviser(cat_change_rules=cat_change_rules)\n",
    "    country_2_continent = Country2ContinentConverter(country_col='native-country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=country_2_contonent_rules)\n",
    "    target_encoder = TargetEncoder(['native-country'])\n",
    "\n",
    "    column_transformer = ColumnTransformer([('Scaler', scaler, num_features), \n",
    "                                            ('One Hot Encoder', one_hot_encoder, cat_features)])\n",
    "\n",
    "    # Define the data transformation pipeline\n",
    "    X_pipeline = Pipeline([('CategoryReviser', category_reviser), \n",
    "                           ('Country2Continent', country_2_continent), \n",
    "                           ('TargetEncoder', target_encoder), \n",
    "                           ('ColumnTransformer', column_transformer),\n",
    "                           ('predictor', predictor)])\n",
    "    \n",
    "    if predictor == None:\n",
    "        X_pipeline.steps.pop()\n",
    "    \n",
    "    return X_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_X_pipeline_partial(predictor=None):\n",
    "    ''' Build pipeline without ethically sensitive features. '''\n",
    "    num_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    cat_features = ['workclass', 'occupation']\n",
    "\n",
    "    cat_change_rules = {'workclass':{'Without-pay':'?', 'Never-worked':'?'},\n",
    "                        'occupation':{'Armed-Forces':'Prof-specialty'}}\n",
    "\n",
    "    # Create and parametatrize data transformers\n",
    "    scaler = StandardScaler()\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    category_reviser = CategoryReviser(cat_change_rules=cat_change_rules)\n",
    "\n",
    "    column_transformer = ColumnTransformer([('Scaler', scaler, num_features), \n",
    "                                            ('One Hot Encoder', one_hot_encoder, cat_features)])\n",
    "\n",
    "    # Define the data transformation pipeline\n",
    "    X_pipeline = Pipeline([('CategoryReviser', category_reviser), \n",
    "                           ('ColumnTransformer', column_transformer),\n",
    "                           ('predictor', predictor)])\n",
    "    \n",
    "    if predictor == None:\n",
    "        X_pipeline.steps.pop()\n",
    "    \n",
    "    return X_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36631, 27), (36631,), (12211, 27), (12211,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_data(columns_to_drop=['marital-status', 'relationship', 'race', \n",
    "                                                             'sex', 'native-country'])\n",
    "y_train_prepared = preprocess_y(y_train)\n",
    "y_test_prepared = preprocess_y(y_test)\n",
    "X_pipeline = build_X_pipeline_partial()\n",
    "X_train_prepared = X_pipeline.fit_transform(X_train, y_train_prepared)\n",
    "X_test_prepared = X_pipeline.transform(X_test)\n",
    "\n",
    "X_train_prepared.shape, y_train_prepared.shape, X_test_prepared.shape, y_test_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Selection\n",
    "Finally, let's train some machine learning models and see what we get!\n",
    "\n",
    "In order to run this, install XGBoost. From your Anaconda prompt, type `pip3 install xgboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import everything we will use\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a performance metric\n",
    "As we learned in Lesson 8, it is a good practice to select a single performance metric that would guide the tuning and selection of models. We are creating a custom metric that is aligned with the business value our model will create:\n",
    "* True positive: \\\\$60 profit\n",
    "* False positive: \\\\$20 loss\n",
    "* True negative: \\\\$20 profit\n",
    "* False negative: \\\\$60 loss\n",
    "\n",
    "See Lesson 8 for more details.\n",
    "\n",
    "[Learn more about metrics and scoring in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_value_score(y_true, y_pred, tp_profit=60, tn_profit=20):\n",
    "    ''' Custom performance metric that calculate the mean monetary profit and loss implications (per row) of our  \n",
    "        predictions, relative to the alternative of targeting all potential customers. \n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    total_profit = tp_profit * (tp - fn) + tn_profit * (tn - fp)\n",
    "    mean_profit = total_profit / len(y_true)\n",
    "    return mean_profit    "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix:**\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "Image by Oritnk, from https://en.wikipedia.org/wiki/File:Binary_confusion_matrix.png. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1],\n",
       "       [2, 3]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is a confusion matrix?\n",
    "a = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0]\n",
    "b = [1, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
    "\n",
    "confusion_matrix(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ravel methods flattens a matrix into a one-dimensional array\n",
    "confusion_matrix(a, b).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_value_score(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.352223405126527"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the maximum value we can get if our model predict everything perfectly\n",
    "mean_value_score(y_test_prepared, y_test_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics of working with predictors\n",
    "Suprisingly, perhaps, training a model and using it for predictions is one of the easiest parts of the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a simple logistic regression\n",
    "log_reg = LogisticRegression(max_iter=1000) # We start with the default parameters, but we may want to increase the number of iterations\n",
    "pipeline_lr = build_X_pipeline_partial(log_reg) # Here, we build a pipeline that includes the logistic regression\n",
    "fitted_pipeline = pipeline_lr.fit(X_train, y_train_prepared) # In this line, we're training the model\n",
    "y_pred = fitted_pipeline.predict(X_test) # In this line, we have the trained model make predictions for the test rows.\n",
    "y_pred[:20] # Show the beginning of the predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.75\n"
     ]
    }
   ],
   "source": [
    "# How did we do?\n",
    "print('%.2f' % mean_value_score(y_test_prepared, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation framework\n",
    "Another thing we need to do early on is selecting a validation framework. Typically we use data in three ways in the training process:\n",
    "* **Training set** - used for traiing the model.\n",
    "* **Validation/development set** - data that is held out of the training and is used to assess the performance of models in order to inform their tuning and select the final model. We will use here a simple, randomized cross validation with five folds.\n",
    "* **Test set** - data that is held out of both training and validation and is used to assess the performance of the selected model on unseen data.\n",
    "\n",
    "[Learn more about evaluating models' preformance with sklearn](https://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'predictor__C': 10.0}\n",
      "Best score 11.47\n"
     ]
    }
   ],
   "source": [
    "# Here is the basic workflow of tuning the hyperparameters of a model\n",
    "custom_scorer = make_scorer(mean_value_score)\n",
    "\n",
    "params = {\n",
    "        'predictor__C': np.logspace(-6, 6, 13),\n",
    "        }\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, params, n_jobs=-1, cv=5, return_train_score=True, scoring=custom_scorer )\n",
    "grid_lr.fit(X_train, y_train_prepared)\n",
    "\n",
    "print('Best Params', grid_lr.best_params_)\n",
    "print('Best score %.2f' % grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.24275079, 0.20704765, 0.18211293, 0.19428067, 0.34786968,\n",
       "        0.53177752, 0.9520524 , 1.01508474, 1.14413977, 0.94587007,\n",
       "        0.94008484, 1.00471258, 0.95086236]),\n",
       " 'std_fit_time': array([0.03245621, 0.02752035, 0.01202799, 0.01172249, 0.01856665,\n",
       "        0.03549879, 0.15817173, 0.18088711, 0.17565463, 0.26608515,\n",
       "        0.16023794, 0.23292831, 0.24039187]),\n",
       " 'mean_score_time': array([0.05086317, 0.04826999, 0.04348316, 0.0452786 , 0.05305815,\n",
       "        0.04926748, 0.07739363, 0.07480006, 0.05944104, 0.07180786,\n",
       "        0.07001252, 0.11269751, 0.04448762]),\n",
       " 'std_score_time': array([0.00721989, 0.01314959, 0.00223925, 0.00857073, 0.00547656,\n",
       "        0.00596986, 0.04079314, 0.02768956, 0.01638389, 0.01428652,\n",
       "        0.01340225, 0.02581586, 0.01945168]),\n",
       " 'param_predictor__C': masked_array(data=[1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                    100.0, 1000.0, 10000.0, 100000.0, 1000000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'predictor__C': 1e-06},\n",
       "  {'predictor__C': 1e-05},\n",
       "  {'predictor__C': 0.0001},\n",
       "  {'predictor__C': 0.001},\n",
       "  {'predictor__C': 0.01},\n",
       "  {'predictor__C': 0.1},\n",
       "  {'predictor__C': 1.0},\n",
       "  {'predictor__C': 10.0},\n",
       "  {'predictor__C': 100.0},\n",
       "  {'predictor__C': 1000.0},\n",
       "  {'predictor__C': 10000.0},\n",
       "  {'predictor__C': 100000.0},\n",
       "  {'predictor__C': 1000000.0}],\n",
       " 'split0_test_score': array([ 0.7069742 ,  0.7069742 ,  1.83704108,  8.34993858, 10.53910195,\n",
       "        11.03043538, 11.06319094, 11.06319094, 11.06319094, 11.06319094,\n",
       "        11.06319094, 11.06319094, 11.06319094]),\n",
       " 'split1_test_score': array([ 0.71526072,  0.71526072,  1.85640186,  8.4029484 , 11.24761125,\n",
       "        11.6025116 , 11.6025116 , 11.6025116 , 11.6025116 , 11.6025116 ,\n",
       "        11.6025116 , 11.6025116 , 11.6025116 ]),\n",
       " 'split2_test_score': array([ 0.71526072,  0.71526072,  1.98744199,  8.55582856, 10.84357084,\n",
       "        11.21485121, 11.31313131, 11.36227136, 11.36227136, 11.37865138,\n",
       "        11.37865138, 11.37865138, 11.36227136]),\n",
       " 'split3_test_score': array([ 0.71526072,  0.71526072,  1.81818182,  8.1954682 , 10.87087087,\n",
       "        11.40595141, 11.50969151, 11.55883156, 11.54245154, 11.54245154,\n",
       "        11.54245154, 11.54245154, 11.54245154]),\n",
       " 'split4_test_score': array([ 0.7043407 ,  0.7043407 ,  1.87824188,  8.94348894, 11.3022113 ,\n",
       "        11.73355173, 11.76631177, 11.76631177, 11.76085176, 11.76085176,\n",
       "        11.76085176, 11.76085176, 11.76085176]),\n",
       " 'mean_test_score': array([ 0.71141941,  0.71141941,  1.87546172,  8.48953454, 10.96067324,\n",
       "        11.39746027, 11.45096743, 11.47062345, 11.46625544, 11.46953144,\n",
       "        11.46953144, 11.46953144, 11.46625544]),\n",
       " 'std_test_score': array([0.00477776, 0.00477776, 0.05944362, 0.25453043, 0.28230532,\n",
       "        0.25421603, 0.24299202, 0.24097641, 0.23850881, 0.23716677,\n",
       "        0.23716677, 0.23716677, 0.23850881]),\n",
       " 'rank_test_score': array([12, 12, 11, 10,  9,  8,  7,  1,  5,  2,  2,  2,  5]),\n",
       " 'split0_train_score': array([ 0.71253071,  0.71253071,  1.88233688,  8.59404859, 11.09200109,\n",
       "        11.57384657, 11.65301665, 11.66257166, 11.66257166, 11.66257166,\n",
       "        11.66257166, 11.66120666, 11.66120666]),\n",
       " 'split1_train_score': array([ 0.71045897,  0.71045897,  1.86657567,  8.45930729, 10.83432861,\n",
       "        11.35983621, 11.38031053, 11.3721208 , 11.3721208 , 11.3721208 ,\n",
       "        11.3721208 , 11.3721208 , 11.3721208 ]),\n",
       " 'split2_train_score': array([ 0.71045897,  0.71045897,  1.85702099,  8.52482512, 10.99539328,\n",
       "        11.43763863, 11.47585736, 11.48814196, 11.49223682, 11.49633168,\n",
       "        11.49633168, 11.49633168, 11.49223682]),\n",
       " 'split3_train_score': array([ 0.71045897,  0.71045897,  1.86930558,  8.52346016, 10.95990445,\n",
       "        11.39805494, 11.45811295, 11.47858727, 11.47722232, 11.47722232,\n",
       "        11.47722232, 11.48131718, 11.47722232]),\n",
       " 'split4_train_score': array([ 0.71318888,  0.71318888,  1.87067053,  8.39651937, 10.84115339,\n",
       "        11.23699027, 11.29841324, 11.31342774, 11.31752261, 11.31752261,\n",
       "        11.31752261, 11.31752261, 11.31752261]),\n",
       " 'mean_train_score': array([ 0.7114193 ,  0.7114193 ,  1.86918193,  8.4996321 , 10.94455616,\n",
       "        11.40127332, 11.45314215, 11.46296989, 11.46433484, 11.46515381,\n",
       "        11.46515381, 11.46569979, 11.46406184]),\n",
       " 'std_train_score': array([0.00119443, 0.00119443, 0.00812361, 0.06689584, 0.09736759,\n",
       "        0.10938032, 0.11809825, 0.11944439, 0.11857462, 0.11877847,\n",
       "        0.11877847, 0.11842184, 0.11811859])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train % [ 0.71  0.71  1.87  8.5  10.94 11.4  11.45 11.46 11.46 11.47 11.47 11.47\n",
      " 11.46]\n",
      "Test [ 0.71  0.71  1.88  8.49 10.96 11.4  11.45 11.47 11.47 11.47 11.47 11.47\n",
      " 11.47]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print('Train %', grid_lr.cv_results_['mean_train_score'])\n",
    "print('Test', grid_lr.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.75\n"
     ]
    }
   ],
   "source": [
    "# This is how we get the test score. However, we should not take it into account at this point. \n",
    "y_pred = grid_lr.predict(X_test) # In this line, we have the trained model make predictions for the test rows.\n",
    "print('%.2f' % mean_value_score(y_test_prepared, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a more sophistic version of logistic regression with:\n",
    "# 1. It can do it's own cross validation.\n",
    "# 2. It can use an Elastic Net penalty, which blends L1 and L2 regularization.\n",
    "log_reg = LogisticRegressionCV(cv=5, solver='saga', penalty='elasticnet', l1_ratios=[0, 0.1, 0.3, 0.5, 0.7, 0.9, 1], n_jobs=-1,\n",
    "                               scoring=custom_scorer, random_state=0, max_iter=1000).fit(X_train_prepared, y_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 11.78\n",
      "Best parameters: l1_ratio 0.00, C 2.78\n"
     ]
    }
   ],
   "source": [
    "print('Best score: %.2f\\nBest parameters: l1_ratio %.2f, C %.2f' % (log_reg.scores_[1].max(), log_reg.l1_ratio_, log_reg.C_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'predictor__max_depth': None, 'predictor__min_samples_leaf': 1}\n",
      "Best score 13.22\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "rf_pipeline = build_X_pipeline_partial(rf)\n",
    "\n",
    "params = {\n",
    "            'predictor__max_depth': [None, 1, 2, 4, 8, 16],\n",
    "            'predictor__min_samples_leaf': [1, 3, 10, 30]\n",
    "         }\n",
    "\n",
    "grid_rf = GridSearchCV(rf_pipeline, params, n_jobs=-1, cv=5, return_train_score=True, scoring=custom_scorer )\n",
    "grid_rf.fit(X_train, y_train_prepared)\n",
    "\n",
    "print('Best Params', grid_rf.best_params_)\n",
    "print('Best score %.2f' % grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can present a predictor with all of its hyperparameters\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'predictor__n_neighbors': 10, 'predictor__weights': 'distance'}\n",
      "Best score 11.75\n"
     ]
    }
   ],
   "source": [
    "# K nearest neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_pipeline = build_X_pipeline_partial(knn)\n",
    "\n",
    "params = {'predictor__weights': ['uniform', 'distance'],\n",
    "          'predictor__n_neighbors': [1, 3, 10, 30, 100]\n",
    "         }\n",
    "\n",
    "grid_knn = GridSearchCV(knn_pipeline, params, n_jobs=-1, cv=5, return_train_score=True, scoring=custom_scorer )\n",
    "grid_knn.fit(X_train, y_train_prepared)\n",
    "\n",
    "print('Best Params', grid_knn.best_params_)\n",
    "print('Best score %.2f' % grid_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'predictor__colsample_bytree': 0.3, 'predictor__learning_rate': 0.1, 'predictor__max_depth': 10, 'predictor__n_estimators': 239, 'predictor__subsample': 0.7}\n",
      "Best score 14.542\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#         'predictor__n_estimators': [10, 50, 90, 130, 170, 210, 250],\n",
    "#         'predictor__learning_rate': [.1],\n",
    "#         'predictor__max_depth': [None, 1, 2, 3, 5, 7, 9, 11, 13],\n",
    "#         'predictor__subsample': [.1, .3, .5, .7, .9, 1],\n",
    "#         'predictor__colsample_bytree': [.1, .3, .5, .7, .9, 1]\n",
    "#         }\n",
    "\n",
    "params = {\n",
    "        'predictor__n_estimators': [239],\n",
    "        'predictor__learning_rate': [.1],\n",
    "        'predictor__max_depth': [10],\n",
    "        'predictor__subsample': [.7],\n",
    "        'predictor__colsample_bytree': [.3]\n",
    "        }\n",
    "\n",
    "xgb = XGBClassifier(n_jobs=-1, random_state=0)\n",
    "\n",
    "xgb_pipeline = build_X_pipeline_partial(xgb)\n",
    "\n",
    "grid_xgb = GridSearchCV(xgb_pipeline, params, n_jobs=-1, cv=5, return_train_score=True, \n",
    "                    scoring=custom_scorer)\n",
    "grid_xgb.fit(X_train, y_train_prepared)\n",
    "\n",
    "print('Best Params', grid_xgb.best_params_)\n",
    "print('Best score %.3f' % grid_xgb.best_score_)\n",
    "# print('Train', grid_xgb.cv_results_['mean_train_score'])\n",
    "# print('Test', grid_xgb.cv_results_['mean_test_score'])\n",
    "#14.541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.843993120956515"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How is our selected model doing on the test set?\n",
    "y_pred = grid_xgb.predict(X_test)\n",
    "mean_value_score(y_test_prepared, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how we're doing with the common Accuracy metric\n",
    "Let's assess ourselves against some solutions out there - we're getting 87.64% accuracy, comparing with [88.16% which was reported in 2018] (https://ieeexplore.ieee.org/abstract/document/8748528) as the best score for ths dataset. Not bad for a quick try! Can you try to improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'TargetEncoder__reg_weight': 20, 'predictor__colsample_bytree': 1, 'predictor__learning_rate': 0.1, 'predictor__max_depth': None, 'predictor__n_estimators': 156, 'predictor__subsample': 1}\n",
      "Best score 0.874\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_jobs=-1, random_state=0)\n",
    "\n",
    "X_train_full, X_test_full, _, _ = get_data(columns_to_drop=None)\n",
    "full_dataset_pipeline = build_X_pipeline_full(xgb)\n",
    "\n",
    "params = {\n",
    "        'TargetEncoder__reg_weight': [20],\n",
    "        'predictor__n_estimators': [156],\n",
    "        'predictor__learning_rate': [.1],\n",
    "        'predictor__max_depth': [None],\n",
    "        'predictor__subsample': [1],\n",
    "        'predictor__colsample_bytree': [1]\n",
    "        }\n",
    "\n",
    "grid_full_ds = GridSearchCV(full_dataset_pipeline, params, n_jobs=-1, cv=5, return_train_score=True)\n",
    "grid_full_ds.fit(X_train_full, y_train_prepared)\n",
    "\n",
    "print('Best Params', grid_full_ds.best_params_)\n",
    "print('Best score %.3f' % grid_full_ds.best_score_)\n",
    "# print('Train', grid_full_ds.cv_results_['mean_train_score'])\n",
    "# print('Test', grid_full_ds.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764228973876014"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_full_ds.score(X_test_full, y_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.139382523953813"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our trained model with the full dataset is having a better performance of about $3.5 per row, even though it is optimized\n",
    "# for a different performance metric.\n",
    "y_pred = grid_full_ds.predict(X_test_full)\n",
    "mean_value_score(y_test_prepared, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab - tuning a gradient boosted tree classifier\n",
    "Tuning a gradient boosted tree, like XGBoost, often works well using the following steps:\n",
    "\n",
    "1. GBC typically performs better the lower its learning rate is, but requires more estimators (and therefore more training time) for lower learning rates. We will start by setting the learning rate of 0.1, and later try to lower it. \n",
    "2. Find the optimal number of trees for this learning rate - this is usually the hyperparameter that has the most influence on the results.\n",
    "3. Tune tree specific parameters.\n",
    "4. Lower the learning rate and increase the number of trees.\n",
    "\n",
    "For demonstration, let's take a version of the dataset with 300 rows and tune it live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 27), (300,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pipeline_full = build_X_pipeline_full()\n",
    "X_train_prepared_full = X_pipeline.fit_transform(X_train, y_train_prepared)\n",
    "X_test_prepared_full = X_pipeline.transform(X_test)\n",
    "y_train_prepared = preprocess_y(y_train)\n",
    "y_test_prepared = preprocess_y(y_test)\n",
    "X_train_300 = X_test_prepared_full[:300]\n",
    "y_train_300 = y_train_prepared[:300]\n",
    "\n",
    "X_train_300.shape, y_train_300.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 240 VALIDATION: 60 Positive rate: 0.25\n",
      "TRAIN: 240 VALIDATION: 60 Positive rate: 0.25\n",
      "TRAIN: 240 VALIDATION: 60 Positive rate: 0.26666666666666666\n",
      "TRAIN: 240 VALIDATION: 60 Positive rate: 0.26666666666666666\n",
      "TRAIN: 240 VALIDATION: 60 Positive rate: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Startified K-fold ensures there are enough positive instances in each validation fold.\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "for train_index, test_index in strat_kfold.split(X_train_300, y_train_300):\n",
    "    print(\"TRAIN:\", len(train_index), \"VALIDATION:\", len(test_index), \"Positive rate:\", \n",
    "          y_train_300[test_index].sum() / len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 157, 'subsample': 0.7}\n",
      "Best score 0.7467\n"
     ]
    }
   ],
   "source": [
    "# Let's go together iteratively through the tuning process\n",
    "\n",
    "xgb_300 = XGBClassifier(n_jobs=-1, random_state=0)\n",
    "\n",
    "# params = {\n",
    "#         'n_estimators': [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210],\n",
    "#         'learning_rate': [.1],\n",
    "#         'max_depth': [None, 1, 2, 3, 5, 7, 9, 11, 13],\n",
    "#         'subsample': [.1, .3, .5, .7, .9, 1],\n",
    "#         'colsample_bytree': [.1, .3, .5, .7, .9, 1]\n",
    "#         }\n",
    "\n",
    "params = {\n",
    "        'n_estimators': [157],\n",
    "        'learning_rate': [.1],\n",
    "        'max_depth': [None, 1, 2, 3, 5, 7, 9, 11, 13],\n",
    "        'subsample': [.1, .3, .5, .7, .9, 1],\n",
    "        'colsample_bytree': [.1, .3, .5, .7, .9, 1]\n",
    "        }\n",
    "\n",
    "grid_full_ds = GridSearchCV(xgb_300, params, n_jobs=-1, cv=strat_kfold.split(X_train_300, y_train_300), \n",
    "                            return_train_score=True)\n",
    "grid_full_ds.fit(X_train_300, y_train_300)\n",
    "\n",
    "print('Best Params', grid_full_ds.best_params_)\n",
    "print('Best score %.4f' % grid_full_ds.best_score_)\n",
    "# print('Train', grid_full_ds.cv_results_['mean_train_score'])\n",
    "# print('Test', grid_full_ds.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [0.99833333 0.99833333 0.99833333 0.99833333 0.99833333 0.99833333\n",
      " 0.99833333 0.99833333]\n",
      "Test [0.72       0.72       0.72       0.72       0.71666667 0.72\n",
      " 0.72       0.72      ]\n"
     ]
    }
   ],
   "source": [
    "print('Train', grid_full_ds.cv_results_['mean_train_score'])\n",
    "print('Test', grid_full_ds.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "Play with different models and see if you can train a model with improved perofrmance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
