{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "\n",
      "Pandas info\n",
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "# Which versions are installed?\n",
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"\\nPandas info\")\n",
    "print (pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "the variable b should have a value of at least 5 , but it is only 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-df863e7f7537>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'the variable b should have a value of at least 5 , but it is only %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: the variable b should have a value of at least 5 , but it is only 3"
     ]
    }
   ],
   "source": [
    "# We use the assert statement to identify bugs in our programs\n",
    "b = 3\n",
    "\n",
    "assert b > 5, 'the variable b should have a value of at least 5 , but it is only %s' % b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we use the assert statement to validate that our data was successfully loaded\n",
    "\n",
    "def get_data():\n",
    "    df_1 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True)\n",
    "    df_2 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True, skiprows=1)\n",
    "    df_combined = df_1.append(df_2, ignore_index=True, sort=True)\n",
    "    \n",
    "    # Check this out -  \n",
    "    assert df_combined.shape == (48842, 15), 'Expected data frame shape:%s; actual:%s' % ((48842, 16), df_combined.shape)\n",
    "\n",
    "    X = df_combined.drop(columns=['>=50K'])\n",
    "    y = df_combined['>=50K']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterStripper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, character_to_strip='.'):\n",
    "        self.character_to_strip = character_to_strip\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X\n",
    "        X_transformed = X_transformed.str.strip(self.character_to_strip)\n",
    "        return X_transformed       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_normal_input():\n",
    "    data = pd.Series(['a.', 'b', 'c...', 'd'])\n",
    "    char_stripper = CharacterStripper('.')\n",
    "    expected = pd.Series(['a', 'b', 'c', 'd'])\n",
    "    actual = char_stripper.fit_transform(data)\n",
    "    pd.testing.assert_series_equal(expected, actual)\n",
    "    \n",
    "test_on_normal_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCountry2ContinentConverter():\n",
    "    def test_on_normal_data_1(self):\n",
    "        data = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'China', 'India', 'U.S.', 'Mexico']})\n",
    "        conversion_rules = {'U.S.':'America',\n",
    "                           'Mexico':'America',\n",
    "                           'China':'Asia',\n",
    "                           'India':'Asia'}\n",
    "        country_2_continent = Country2ContinentConverter(country_col='country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=conversion_rules)\n",
    "        expected = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'China', 'India', 'U.S.', 'Mexico'],\n",
    "                             'continent':['America', 'Asia', 'Asia', 'America', 'America']})\n",
    "        actual = country_2_continent.fit_transform(data)\n",
    "        pd.testing.assert_frame_equal(expected, actual)\n",
    "\n",
    "    def test_on_normal_data_2(self):\n",
    "        pass\n",
    "    \n",
    "    def test_on_missing_value(self):\n",
    "        data = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', np.nan, 'India', 'U.S.', 'Mexico']})\n",
    "        conversion_rules = {'U.S.':'America',\n",
    "                           'Mexico':'America',\n",
    "                           'China':'Asia',\n",
    "                           'India':'Asia'}\n",
    "        country_2_continent = Country2ContinentConverter(country_col='country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=conversion_rules)\n",
    "        expected = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', '', 'India', 'U.S.', 'Mexico'],\n",
    "                             'continent':['America', '', 'Asia', 'America', 'America']})\n",
    "        actual = country_2_continent.fit_transform(data)\n",
    "        pd.testing.assert_frame_equal(expected, actual)\n",
    "    \n",
    "    def test_on_unknown_value(self):\n",
    "        data = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'Argentina', 'India', 'U.S.', 'Mexico']})\n",
    "        conversion_rules = {'U.S.':'America',\n",
    "                           'Mexico':'America',\n",
    "                           'China':'Asia',\n",
    "                           'India':'Asia'}\n",
    "        country_2_continent = Country2ContinentConverter(country_col='country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=conversion_rules)\n",
    "        expected = pd.DataFrame({'number':[1, 2, 3, 4, 5],\n",
    "                            'country':['U.S.', 'Argentina', 'India', 'U.S.', 'Mexico'],\n",
    "                             'continent':['America', '', 'Asia', 'America', 'America']})\n",
    "        actual = country_2_continent.fit_transform(data)\n",
    "        pd.testing.assert_frame_equal(expected, actual)\n",
    "    \n",
    "    def test_on_missing_column(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country_2_continent = TestCountry2ContinentConverter()\n",
    "test_country_2_continent.test_on_normal_data_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country_2_continent.test_on_missing_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country_2_continent.test_on_unknown_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.4, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: C:\\Users\\tyifat\\Workspace\\python-for-dna\\Season 2\\lesson 12\n",
      "collected 1 item\n",
      "\n",
      "tests\\test_custom_transformers.py F                                      [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "_________________ TestCharacterStripper.test_on_normal_input __________________\n",
      "\n",
      "self = <test_custom_transformers.TestCharacterStripper object at 0x000001F10FD8C308>\n",
      "\n",
      "    def test_on_normal_input(self):\n",
      "        data = pd.Series(['a.', 'b', 'c...', 'd'])\n",
      "        char_stripper = CharacterStripper(character_to_strip='.')\n",
      "        expected = pd.Series(['a', 'b', 'c', 'dc'])\n",
      "        actual = char_stripper.fit_transform(data)\n",
      ">       pd.testing.assert_series_equal(expected, actual)\n",
      "\n",
      "tests\\test_custom_transformers.py:16: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "pandas/_libs/testing.pyx:65: in pandas._libs.testing.assert_almost_equal\n",
      "    ???\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      ">   ???\n",
      "E   AssertionError: Series are different\n",
      "E   \n",
      "E   Series values are different (25.0 %)\n",
      "E   [left]:  [a, b, c, dc]\n",
      "E   [right]: [a, b, c, d]\n",
      "\n",
      "pandas/_libs/testing.pyx:178: AssertionError\n",
      "============================== 1 failed in 1.51s ==============================\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that changes category names according to specified rules\n",
    "class CategoryReviser(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer revises categories according to a dictionary with rules '''\n",
    "    def __init__(self, cat_change_rules={}):\n",
    "        self.cat_change_rules = cat_change_rules\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feature in self.cat_change_rules:\n",
    "            for cat in self.cat_change_rules[feature]:\n",
    "                X_transformed.loc[X[feature]==cat, feature] = self.cat_change_rules[feature][cat]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that changes category names according to specified rules\n",
    "class Country2ContinentConverter(BaseEstimator, TransformerMixin):\n",
    "    ''' This transformer revises categories according to a dictionary with rules '''\n",
    "    def __init__(self, country_col='native-country', continent_col='continent', conversion_rules={}):\n",
    "        self.country_col = country_col\n",
    "        self.continent_col = continent_col\n",
    "        self.conversion_rules = conversion_rules\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.continent_col] = \"\"\n",
    "        for country in self.conversion_rules:\n",
    "            X_transformed.loc[X[self.country_col]==country, self.continent_col] = self.conversion_rules[country]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, reg_weight=20):\n",
    "        self.features = features\n",
    "        self.reg_weight = reg_weight\n",
    "        self.mapping = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_positive_rate = y.mean()\n",
    "        X_y = X.copy()\n",
    "        X_y['target'] = y\n",
    "        for feat in self.features:\n",
    "            cat_positive_rates = {}\n",
    "            for feat in self.features:\n",
    "                self.mapping[feat] = {}\n",
    "                positive_rates = X_y.groupby(feat)['target'].mean()\n",
    "                value_counts = X_y[feat].value_counts()\n",
    "                for cat in X_y[feat].unique():\n",
    "                    n = value_counts.loc[cat]\n",
    "                    rate = positive_rates.loc[cat]\n",
    "                    regularized_rate = (rate * n + X_positive_rate * self.reg_weight) / (n + self.reg_weight)\n",
    "                    self.mapping[feat][cat] = regularized_rate\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for feat in self.mapping:\n",
    "            for cat in self.mapping[feat]:\n",
    "                X_transformed.loc[X[feat]==cat, feat] = self.mapping[feat][cat]\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df_1 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True)\n",
    "    df_2 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", \n",
    "                   names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                   'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                   'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   '>=50K'], skipinitialspace=True, skiprows=1)\n",
    "    df_combined = df_1.append(df_2, ignore_index=True, sort=True)\n",
    "    X = df_combined.drop(columns=['>=50K'])\n",
    "    y = df_combined['>=50K']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_y(y):\n",
    "    character_stripper = CharacterStripper(character_to_strip='.')\n",
    "    y_stripped = character_stripper.fit_transform(y_train)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_prepared = label_encoder.fit_transform(y_stripped)\n",
    "    return y_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_X_pipeline():\n",
    "    num_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',]\n",
    "    cat_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'continent']\n",
    "\n",
    "    cat_change_rules = {'marital-status':{'Married-AF-spouse':'Married', 'Married-civ-spouse':'Married'}, \n",
    "                        'workclass':{'Without-pay':'?', 'Never-worked':'?'},\n",
    "                        'occupation':{'Armed-Forces':'Prof-specialty'}}\n",
    "    country_2_contonent_rules = {'United-States':'N-America',\n",
    "                         'Germany':'Europe',\n",
    "                         'Mexico':'LatAm',\n",
    "                         'Scotland':'Europe',\n",
    "                         'Peru':'LatAm',\n",
    "                         'Honduras':'LatAm',\n",
    "                         'Ecuador':'LatAm',\n",
    "                         'Poland':'Europe',\n",
    "                         'China':'Asia',\n",
    "                         'Nicaragua':'LatAm',\n",
    "                         'India':'Asia',\n",
    "                         'Philippines':'Asia',\n",
    "                         'Iran':'Asia',\n",
    "                         'Japan':'Asia',\n",
    "                         'Vietnam':'Asia',\n",
    "                         'Dominican-Republic':'LatAm',\n",
    "                         'Ireland':'Europe',\n",
    "                         'Laos':'Asia',\n",
    "                         'Jamaica':'LatAm',\n",
    "                         'England':'Europe',\n",
    "                         'Hong':'Asia',\n",
    "                         'Puerto-Rico':'LatAm',\n",
    "                         'Cuba':'LatAm',\n",
    "                         'Haiti':'LatAm',\n",
    "                         'Guatemala':'LatAm',\n",
    "                         'El-Salvador':'LatAm',\n",
    "                         'Columbia':'LatAm',\n",
    "                         'Italy':'Europe',\n",
    "                         'Taiwan':'Asia',\n",
    "                         'Canada':'N-America',\n",
    "                         'Portugal':'Europe',\n",
    "                         'Thailand':'Asia',\n",
    "                         'Cambodia':'Asia',\n",
    "                         'France':'Europe',\n",
    "                         'Greece':'Europe',\n",
    "                         'Trinadad&Tobago':'LatAm',\n",
    "                         'Yugoslavia':'Europe',\n",
    "                         'Hungary':'Europe',\n",
    "                         'Holand-Netherlands':'Europe',\n",
    "                        }\n",
    "\n",
    "    # Create and parametatrize data transformers\n",
    "    scaler = StandardScaler()\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    category_reviser = CategoryReviser(cat_change_rules=cat_change_rules)\n",
    "    country_2_continent = Country2ContinentConverter(country_col='native-country', \n",
    "                                                     continent_col='continent', \n",
    "                                                     conversion_rules=country_2_contonent_rules)\n",
    "    target_encoder = TargetEncoder(['native-country'])\n",
    "\n",
    "    column_transformer = ColumnTransformer([('Scaler', scaler, num_features), \n",
    "                                            ('One Hot Encoder', one_hot_encoder, cat_features)])\n",
    "\n",
    "    # Define the data transformation pipeline\n",
    "    X_pipeline = Pipeline([('Category Reviser', category_reviser), \n",
    "                           ('Country to Continent', country_2_continent), \n",
    "                           ('Target Encoder', target_encoder), \n",
    "                           ('ColumnTransformer', column_transformer)])\n",
    "    return X_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36631, 52), (36631,), (12211, 52), (36631,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_data()\n",
    "y_train_prepared = preprocess_y(y_train)\n",
    "y_test_prepared = preprocess_y(y_test)\n",
    "X_pipeline = X_pipeline\n",
    "X_train_prepared = X_pipeline.fit_transform(X_train, y_train_prepared)\n",
    "X_test_prepared = X_pipeline.transform(X_test)\n",
    "\n",
    "X_train_prepared.shape, y_train_prepared.shape, X_test_prepared.shape, y_test_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
